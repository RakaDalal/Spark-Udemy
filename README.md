# Spark-Udemy

This repository contains all codes created during the online course by Udemy.

# What I learnt from this course:

1. Use DataFrames and Structured Streaming in Spark 2
2. Frame big data analysis problems as Spark problems
3. Use Amazon's Elastic MapReduce service to run your job on a cluster with Hadoop YARN
4. Install and run Apache Spark on a desktop computer or on a cluster
5. Use Spark's Resilient Distributed Datasets to process and analyze large data sets across many CPU's
6. Implement iterative algorithms such as breadth-first-search using Spark
7. Use the MLLib machine learning library to answer common data mining questions
8. Understand how Spark SQL lets you work with structured data
9. Understand how Spark Streaming lets your process continuous streams of data in real time
10. Tune and troubleshoot large jobs running on a cluster
11. Share information between nodes on a Spark cluster using broadcast variables and accumulators
12. Understand how the GraphX library helps with network analysis problems

# Some sample big data analysis problems that we solved as Spark problems:

1. Designed a movie-recommendation system using Item-Based Collaborative Filtering.
2. Analyzed degrees of separation problem in Social Network using breadth-first search.
